# Wikipedia history analysis using HBase


Develop the connection with HBase table by proceeding with two task given in the specification and analyze their efficiency and also optimize them as required. Consequently, implemented the corresponding programs and analyzed on the basis of processing time, no. of bytes read from HDFS and no of bytes transferred over network with some other metrics as well like Total megabyte-seconds taken by all map/reduce tasks to check how filters and cache is making difference in the performance. In the proceeding report we discuss about the implementation and evaluation stages. 


#Part 1 -> Count the number of changes done for an article in the given input time interval also finding the corresponding revision id. 

#Part 2 -> Get the article id and particular revision id that is current at the given timestamp.
